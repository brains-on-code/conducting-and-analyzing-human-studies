{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2407c32d64e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mz_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'task'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mz_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'task'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   2530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_box_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2532\u001b[1;33m         \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2481\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2483\u001b[1;33m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in data\n",
    "z_data = pd.read_csv('fse17_act_deact_zscore_groups.csv',sep=';',decimal='.')\n",
    "\n",
    "# Remove irrelevant columns\n",
    "z_data.drop(list(z_data.filter(regex = '_act')),axis = 1, inplace = True)\n",
    "z_data.drop(list(z_data.filter(regex = 'aggr')),axis = 1, inplace = True)\n",
    "data = z_data# necessary, because task and proband are dropped for the learning\n",
    "\n",
    "#we need the list with the labels to test the predictions; everytime the label or proband changes, we add it to the list\n",
    "labelsComputingAccuracy = []\n",
    "\n",
    "condition = z_data.at[0, 'task']\n",
    "participant = z_data.at[0, 'proband']\n",
    "    \n",
    "for i in range(len(z_data)):\n",
    "    if condition != z_data.at[i, 'task'] or participant != z_data.at[i, 'proband']:\n",
    "#         print(participant,i)\n",
    "        labelsComputingAccuracy.append(condition)\n",
    "        condition = z_data.at[i, 'task']\n",
    "        participant = z_data.at[i, 'proband']\n",
    "#         print(participant,i)\n",
    "labelsComputingAccuracy.append(condition)\n",
    "\n",
    "# recode word labels to num labels so t_pot can handle the lables =======\n",
    "labels = []\n",
    "for i in range(len(z_data)):\n",
    "    if z_data.at[i,'task'] == 0:\n",
    "        labels.append(0)\n",
    "    if z_data.at[i,'task'] == 1:\n",
    "        labels.append(1)\n",
    "    if z_data.at[i,'task'] == 2:\n",
    "        labels.append(2)\n",
    "\n",
    "#=== remove everything that is not a feature ===================================================\n",
    "z_data = z_data.drop('proband', axis = 1)\n",
    "z_data = z_data.drop('scan', axis = 1)\n",
    "z_data = z_data.drop('trial', axis = 1)\n",
    "z_data = z_data.drop('task', axis = 1)\n",
    "z_data = z_data.drop('snippet', axis = 1)\n",
    "z_data = z_data.drop('response', axis = 1)\n",
    "\n",
    "#=== creating training and validation set ======================================================\n",
    "# Saving feature names for later use\n",
    "feature_list = z_data.columns\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(z_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "#split the data into train and validation set\n",
    "#get the rows excluding the last indexed (i.e., row with the index 10973 is the last to include)\n",
    "#the rows until 10973 contain the first 12 participants, the remaining rows the last 4\n",
    "training_features = features[0:9570]\n",
    "training_features = np.array(training_features)\n",
    "testing_features = features[9570:12180]\n",
    "testing_features = np.array(testing_features)\n",
    "\n",
    "training_target = labels[0:9570]\n",
    "training_target = np.array(training_target)\n",
    "testing_target = labels[9570:12180]\n",
    "testing_target = np.array(testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\author\\Anaconda3\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "C:\\Users\\author\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\author\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\author\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\author\\Anaconda3\\lib\\importlib\\_bootstrap_external.py:426: ImportWarning: Not importing directory C:\\Users\\author\\Anaconda3\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n",
      "C:\\Users\\author\\Anaconda3\\lib\\importlib\\_bootstrap_external.py:426: ImportWarning: Not importing directory c:\\users\\author\\anaconda3\\lib\\site-packages\\mpl_toolkits: missing __init__\n",
      "  _warnings.warn(msg.format(portions[0]), ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "fileNameTPot = 'Deact/tpot_mnist_pipeline_NotAggregatedParticipantSplit'\n",
    "\n",
    "# tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2, n_jobs=20)\n",
    "# tpot.fit(training_features, training_target)\n",
    "# print(tpot.score(testing_features, testing_target))\n",
    "# tpot.export(fileNameTPot + '.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileNameTPot + '.py') as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "# content = [x.strip() for x in content] \n",
    "\n",
    "#      or 'exported_pipeline = ' not in line\n",
    "cleanedContent = []\n",
    "for line in content:\n",
    "    if 'tpot_data' not in line and 'training_target, testing_target' not in line:\n",
    "        cleanedContent.append(line)\n",
    "#         content.remove(line)\n",
    "\n",
    "fileForLearning = fileNameTPot + '_cleaned.py'\n",
    "with open(fileForLearning, 'w') as filehandle:  \n",
    "    for line in cleanedContent:\n",
    "        filehandle.write('%s\\n' % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_data = data # necessary, because task and proband are dropped for the learning\n",
    "condition = z_data.at[9570, 'task']\n",
    "participant = z_data.at[9570, 'proband']\n",
    "majorityVote = []\n",
    "labelsForAcc = []\n",
    "countComprehension = 0\n",
    "countRest = 0\n",
    "    \n",
    "for i,j in zip(range(9570,len(z_data)),range(len(results))):\n",
    "    if condition != z_data.at[i, 'task'] or participant != z_data.at[i, 'proband']:\n",
    "        labelsForAcc.append(condition)\n",
    "        condition = z_data.at[i, 'task']\n",
    "        participant = z_data.at[i, 'proband']\n",
    "        if countComprehension > countRest:\n",
    "            majorityVote.append('C')\n",
    "        elif countRest > countComprehension:\n",
    "            majorityVote.append('R')\n",
    "        else:\n",
    "            majorityVote.append('CR')\n",
    "        countComprehension = 0\n",
    "        countRest = 0\n",
    "\n",
    "    if (results[j] == 0):\n",
    "        countComprehension = countComprehension + 1\n",
    "    if (results[j] == 1):\n",
    "        countRest = countRest + 1\n",
    "\n",
    "labelsForAcc.append(condition)\n",
    "if (results[j] == 0):\n",
    "    countComprehension = countComprehension + 1\n",
    "if (results[j] == 1):\n",
    "    countRest = countRest + 1\n",
    "\n",
    "if countComprehension > countRest:\n",
    "    majorityVote.append('C')\n",
    "elif countRest > countComprehension:\n",
    "    majorityVote.append('R')\n",
    "else:\n",
    "    majorityVote.append('CR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 112 (of 165 )\n",
      "Accuary:  67.87878787878789\n"
     ]
    }
   ],
   "source": [
    "labelsForAcc = pd.Series(labelsForAcc)\n",
    "labelsForAcc = labelsForAcc.replace({0: 'C', 1: 'R', 2: 'S'})\n",
    "\n",
    "num_matches = 0;\n",
    "for a, b in zip(majorityVote, labelsForAcc):\n",
    "    if b in a:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',len(labelsForAcc),')')\n",
    "\n",
    "accuracy = num_matches/len(labelsForAcc)*100\n",
    "print('Accuary: ',accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listOfAccuracies.txt','a+') as f:\n",
    "    f.write('%s\\n' % 'NoAgg_Deact' + str(accuracy) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
