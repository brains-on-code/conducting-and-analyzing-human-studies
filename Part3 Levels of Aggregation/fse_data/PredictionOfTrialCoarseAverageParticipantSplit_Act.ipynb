{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\author\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in data\n",
    "z_data = pd.read_csv('fse17_act_deact_zscore_groups.csv',sep=';',decimal='.')\n",
    "\n",
    "# Remove irrelevant columns\n",
    "z_data.drop(list(z_data.filter(regex = '_deact')),axis = 1, inplace = True)\n",
    "z_data.drop(list(z_data.filter(regex = 'aggr')),axis = 1, inplace = True)\n",
    "\n",
    "# === drop all columns that are not necessary for learning =====================================\n",
    "z_data = z_data.drop('scan', axis = 1)\n",
    "z_data = z_data.drop('trial', axis = 1)\n",
    "z_data = z_data.drop('snippet', axis = 1)\n",
    "z_data = z_data.drop('response', axis = 1)\n",
    "\n",
    "#=== now create the different groups and compute the groupwise mean ============================\n",
    "grouped = z_data.groupby(['proband', 'task'])\n",
    "groupedAgg = grouped.aggregate(np.mean)\n",
    "labels = groupedAgg.index.get_level_values(level='task')\n",
    "#=== end aggregation ===========================================================================\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(groupedAgg.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(groupedAgg)\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "numLabels = 2 # num of different labels (comprehension and rest)\n",
    "sizeTrainSet = 11 # num of participants used for training\n",
    "sizeTestSet = 3 # num participants used for testing\n",
    "numParticipants = sizeTrainSet + sizeTestSet\n",
    "\n",
    "#get the rows excluding the last indexed (i.e., row with the index 35 is the last to include)\n",
    "training_features = features[0:numLabels*sizeTrainSet]\n",
    "training_features = np.array(training_features)\n",
    "testing_features = features[numLabels*sizeTrainSet:numLabels*numParticipants]\n",
    "testing_features = np.array(testing_features)\n",
    "\n",
    "training_target = labels[0:numLabels*sizeTrainSet]\n",
    "training_target = np.array(training_target)\n",
    "testing_target = labels[numLabels*sizeTrainSet:numLabels*numParticipants]\n",
    "testing_target = np.array(testing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 390)\n",
      "(6, 390)\n",
      "(22,)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "print(training_features.shape)\n",
    "print(testing_features.shape)\n",
    "print(training_target.shape)\n",
    "print(testing_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNameTPot = 'Act/tpot_mnist_pipeline_CoarseAverageParticipantSplit_Act'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: GaussianNB(input_matrix)\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, verbosity=2, n_jobs=20)\n",
    "tpot.fit(training_features, training_target)\n",
    "print(tpot.score(testing_features, testing_target))\n",
    "tpot.export(fileNameTPot + '.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileNameTPot + '.py') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "cleanedContent = []\n",
    "for line in content:\n",
    "    if 'tpot_data' not in line and 'training_target, testing_target' not in line:\n",
    "        cleanedContent.append(line)\n",
    "\n",
    "fileForLearning = fileNameTPot + '_cleaned.py'\n",
    "with open(fileForLearning, 'w') as filehandle:  \n",
    "    for line in cleanedContent:\n",
    "        filehandle.write('%s\\n' % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2 to 7 =============================================\n",
    "indecesTrain = []\n",
    "indecesTest = []\n",
    "for i in range(len(labels)):\n",
    "    if i%numParticipants <= 2 or i%numParticipants >= 6:\n",
    "        indecesTrain.append(i)\n",
    "    else:\n",
    "        indecesTest.append(i)\n",
    "\n",
    "training_features = np.take(features,indecesTrain,axis=0)\n",
    "testing_features = np.take(features,indecesTest,axis=0)\n",
    "\n",
    "training_target = np.take(labels,indecesTrain,axis=0)\n",
    "testing_target = np.take(labels,indecesTest,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(indecesTrain))\n",
    "print(len(indecesTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 6 (of 6 )\n",
      "Accuary:  100.0\n"
     ]
    }
   ],
   "source": [
    "finalAccuracy = 0\n",
    "num_matches = 0;\n",
    "for a, b in zip(testing_target, results):\n",
    "    if a == b:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',testing_target.size,')')\n",
    "\n",
    "accuracy = num_matches/testing_target.size*100\n",
    "print('Accuary: ',accuracy)\n",
    "\n",
    "if accuracy > finalAccuracy:\n",
    "    finalAccuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4 to 9 =============================================\n",
    "indecesTrain = []\n",
    "indecesTest = []\n",
    "for i in range(len(labels)):\n",
    "    if i%numParticipants <= 4 or i%numParticipants >= 8:\n",
    "        indecesTrain.append(i)\n",
    "    else:\n",
    "        indecesTest.append(i)\n",
    "\n",
    "training_features = np.take(features,indecesTrain,axis=0)\n",
    "testing_features = np.take(features,indecesTest,axis=0)\n",
    "\n",
    "training_target = np.take(labels,indecesTrain,axis=0)\n",
    "testing_target = np.take(labels,indecesTest,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 6 (of 6 )\n",
      "Accuary:  100.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = 0;\n",
    "for a, b in zip(testing_target, results):\n",
    "    if a == b:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',testing_target.size,')')\n",
    "\n",
    "accuracy = num_matches/testing_target.size*100\n",
    "print('Accuary: ',accuracy)\n",
    "\n",
    "if accuracy > finalAccuracy:\n",
    "    finalAccuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6 to 11 =============================================\n",
    "indecesTrain = []\n",
    "indecesTest = []\n",
    "for i in range(len(labels)):\n",
    "    if i%numParticipants <= 6 or i%numParticipants >= 10:\n",
    "        indecesTrain.append(i)\n",
    "    else:\n",
    "        indecesTest.append(i)\n",
    "\n",
    "training_features = np.take(features,indecesTrain,axis=0)\n",
    "testing_features = np.take(features,indecesTest,axis=0)\n",
    "\n",
    "training_target = np.take(labels,indecesTrain,axis=0)\n",
    "testing_target = np.take(labels,indecesTest,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 6 (of 6 )\n",
      "Accuary:  100.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = 0;\n",
    "for a, b in zip(testing_target, results):\n",
    "    if a == b:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',testing_target.size,')')\n",
    "\n",
    "accuracy = num_matches/testing_target.size*100\n",
    "print('Accuary: ',accuracy)\n",
    "\n",
    "if accuracy > finalAccuracy:\n",
    "    finalAccuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8 to 13 =============================================\n",
    "indecesTrain = []\n",
    "indecesTest = []\n",
    "for i in range(len(labels)):\n",
    "    if i%numParticipants <= 8 or i%numParticipants >= 12:\n",
    "        indecesTrain.append(i)\n",
    "    else:\n",
    "        indecesTest.append(i)\n",
    "\n",
    "training_features = np.take(features,indecesTrain,axis=0)\n",
    "testing_features = np.take(features,indecesTest,axis=0)\n",
    "\n",
    "training_target = np.take(labels,indecesTrain,axis=0)\n",
    "testing_target = np.take(labels,indecesTest,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 6 (of 6 )\n",
      "Accuary:  100.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = 0;\n",
    "for a, b in zip(testing_target, results):\n",
    "    if a == b:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',testing_target.size,')')\n",
    "\n",
    "accuracy = num_matches/testing_target.size*100\n",
    "print('Accuary: ',accuracy)\n",
    "\n",
    "if accuracy > finalAccuracy:\n",
    "    finalAccuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 10 to 15 =============================================\n",
    "indecesTrain = []\n",
    "indecesTest = []\n",
    "for i in range(len(labels)):\n",
    "    if i%numParticipants <= 9 or i%numParticipants >= 13:\n",
    "        indecesTrain.append(i)\n",
    "    else:\n",
    "        indecesTest.append(i)\n",
    "\n",
    "training_features = np.take(features,indecesTrain,axis=0)\n",
    "testing_features = np.take(features,indecesTest,axis=0)\n",
    "\n",
    "training_target = np.take(labels,indecesTrain,axis=0)\n",
    "testing_target = np.take(labels,indecesTest,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i $fileForLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 6 (of 6 )\n",
      "Accuary:  100.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = 0;\n",
    "for a, b in zip(testing_target, results):\n",
    "    if a == b:\n",
    "        num_matches = num_matches + 1\n",
    "print('Number of matches:',num_matches,'(of',testing_target.size,')')\n",
    "\n",
    "accuracy = num_matches/testing_target.size*100\n",
    "print('Accuary: ',accuracy)\n",
    "\n",
    "if accuracy > finalAccuracy:\n",
    "    finalAccuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listOfAccuracies.txt','a+') as f:\n",
    "    f.write('%s\\n' % 'Coarse_Act' + str(finalAccuracy) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
